{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "add42d36",
   "metadata": {},
   "source": [
    "#### Лабораторная работа № 3. Разработка нейросетевых функций. Операция Convolution Transpose\n",
    "#### БВТ2003 Суроп Максим Андреевич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cfafbcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "daae9537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvTranspose(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "                 output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros'):\n",
    "        super(ConvTranspose, self).__init__()\n",
    "\n",
    "        # Сохранение параметров\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.output_padding = output_padding\n",
    "        self.dilation = dilation\n",
    "        self.groups = groups\n",
    "        self.bias = bias\n",
    "        self.padding_mode = padding_mode\n",
    "\n",
    "        # Инициализация параметров\n",
    "        self.weight = nn.Parameter(torch.rand(out_channels, in_channels, *kernel_size))\n",
    "        self.bias_param = nn.Parameter(torch.rand(out_channels)) if bias else None\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Проверка режима паддинга\n",
    "        if self.padding_mode != 'zeros':\n",
    "            raise ValueError('Поддерживается только режим паддинга \"zeros\" в ConvTranspose2d')\n",
    "\n",
    "        # Инвертирование пространственных размеров ядра для ConvTranspose2d\n",
    "        filter_for_transpose = torch.flip(self.weight, [2, 3])\n",
    "\n",
    "        # Операция ConvTranspose2d\n",
    "        out_tensor = F.conv_transpose2d(\n",
    "            input, filter_for_transpose, bias=self.bias_param,\n",
    "            stride=self.stride, padding=self.padding, output_padding=self.output_padding,\n",
    "            dilation=self.dilation, groups=1  # groups=1, так как в текущей реализации нет поддержки групп\n",
    "        )\n",
    "\n",
    "        # Применение паддинга для output_padding\n",
    "        if self.output_padding > 0:\n",
    "            pad_func = nn.ConstantPad2d((0, self.output_padding, 0, self.output_padding), 0)\n",
    "            out_tensor = pad_func(out_tensor)\n",
    "\n",
    "        # Обрезка результата по краям\n",
    "        out_tensor = out_tensor[:, :, self.padding:out_tensor.shape[2] - self.padding,\n",
    "                                   self.padding:out_tensor.shape[3] - self.padding]\n",
    "\n",
    "        # Округление значений с повышенной точностью\n",
    "        rounded_result = torch.round(out_tensor * 1e9) / 1e9\n",
    "\n",
    "        return rounded_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35b942e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conv_transpose():\n",
    "    conv_transpose = ConvTranspose(\n",
    "        in_channels=1, out_channels=1, kernel_size=(3, 3),\n",
    "        stride=2, padding=1, output_padding=1\n",
    "    )\n",
    "    x = torch.ones((1, 1, 4, 4))  # Входные данные\n",
    "    result = conv_transpose.forward(x)\n",
    "    print(\"Тестовый пример:\")\n",
    "    print(f\"Input:\\n{x}\\n\")\n",
    "    print(f\"Output:\\n{result}\")\n",
    "\n",
    "    # тестирование с использованием torch.nn.functional.conv_transpose2d\n",
    "    filter_for_transpose = torch.flip(conv_transpose.weight, [2, 3])\n",
    "    expected_result = F.conv_transpose2d(\n",
    "        x, filter_for_transpose, bias=conv_transpose.bias_param,\n",
    "        stride=conv_transpose.stride, padding=conv_transpose.padding,\n",
    "        output_padding=conv_transpose.output_padding, dilation=conv_transpose.dilation, groups=1\n",
    "    )\n",
    "    print(f\"\\nОжидаемый результат:\\n{expected_result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "709b54d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестовый пример:\n",
      "Input:\n",
      "tensor([[[[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]]]])\n",
      "\n",
      "Output:\n",
      "tensor([[[[3.5776, 1.2528, 3.5776, 1.2528, 3.5776, 1.2528, 1.9369],\n",
      "          [1.9629, 1.2574, 1.9629, 1.2574, 1.9629, 1.2574, 1.4950],\n",
      "          [3.5776, 1.2528, 3.5776, 1.2528, 3.5776, 1.2528, 1.9369],\n",
      "          [1.9629, 1.2574, 1.9629, 1.2574, 1.9629, 1.2574, 1.4950],\n",
      "          [3.5776, 1.2528, 3.5776, 1.2528, 3.5776, 1.2528, 1.9369],\n",
      "          [1.9629, 1.2574, 1.9629, 1.2574, 1.9629, 1.2574, 1.4950],\n",
      "          [2.3578, 1.1839, 2.3578, 1.1839, 2.3578, 1.1839, 1.6338]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "\n",
      "Ожидаемый результат:\n",
      "tensor([[[[1.2574, 1.9629, 1.2574, 1.9629, 1.2574, 1.9629, 1.2574, 1.4950],\n",
      "          [1.2528, 3.5776, 1.2528, 3.5776, 1.2528, 3.5776, 1.2528, 1.9369],\n",
      "          [1.2574, 1.9629, 1.2574, 1.9629, 1.2574, 1.9629, 1.2574, 1.4950],\n",
      "          [1.2528, 3.5776, 1.2528, 3.5776, 1.2528, 3.5776, 1.2528, 1.9369],\n",
      "          [1.2574, 1.9629, 1.2574, 1.9629, 1.2574, 1.9629, 1.2574, 1.4950],\n",
      "          [1.2528, 3.5776, 1.2528, 3.5776, 1.2528, 3.5776, 1.2528, 1.9369],\n",
      "          [1.2574, 1.9629, 1.2574, 1.9629, 1.2574, 1.9629, 1.2574, 1.4950],\n",
      "          [1.1839, 2.3578, 1.1839, 2.3578, 1.1839, 2.3578, 1.1839, 1.6338]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_conv_transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cc153a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84b9504a",
   "metadata": {},
   "source": [
    "#### Дополнительное задание :\n",
    "#### Необходимо реализовать алгоритм работы транспонированной свертки через алгоритм двумерной свертки, реализованный в первой лабораторной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "779b765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "be56a9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DTranspose:\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: Union[int, tuple], stride: Union[int, tuple] = 1) -> None:\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = (kernel_size, kernel_size) if isinstance(kernel_size, int) else kernel_size\n",
    "        self.stride = (stride, stride) if isinstance(stride, int) else stride\n",
    "\n",
    "        # Инициализация весов (транспонированное ядро свертки) и смещений\n",
    "        self.weights = np.random.randn(in_channels, out_channels, *self.kernel_size)\n",
    "        self.bias = np.zeros((out_channels,))\n",
    "\n",
    "    def forward(self, input_tensor: np.ndarray) -> np.ndarray:\n",
    "        batch_size, in_channels, input_height, input_width = input_tensor.shape\n",
    "        kernel_size = self.kernel_size\n",
    "\n",
    "        # Вычисление размеров результата транспонированной свертки\n",
    "        stride_h, stride_w = self.stride\n",
    "        output_height = (input_height - 1) * stride_h + kernel_size[0]\n",
    "        output_width = (input_width - 1) * stride_w + kernel_size[1]\n",
    "\n",
    "        # Инициализация результата транспонированной свертки\n",
    "        result = np.zeros((batch_size, self.out_channels, output_height, output_width))\n",
    "\n",
    "        # Выполнение транспонированной свертки\n",
    "        for i in range(input_height):\n",
    "            for j in range(input_width):\n",
    "                window = input_tensor[:, :, i, j]\n",
    "                result[:, :, i * stride_h:i * stride_h + kernel_size[0], j * stride_w:j * stride_w + kernel_size[1]] += \\\n",
    "                    np.tensordot(window, self.weights, axes=(1, 0))\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cba47aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_transpose_test(in_channels: int, out_channels: int, kernel_size: Union[int, tuple], stride: Union[int, tuple],\n",
    "                       padding: Union[int, tuple], dilation: int, groups: int, bias: bool, padding_mode: str) -> None:\n",
    "    # Создание экземпляра Conv2DTranspose\n",
    "    conv_transpose_layer = Conv2DTranspose(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
    "\n",
    "    # Создание тензора для теста\n",
    "    input_tensor = np.random.randn(1, in_channels, 10, 10)\n",
    "\n",
    "    # Выполнение транспонированной свертки\n",
    "    result_conv2d_transpose = conv_transpose_layer.forward(input_tensor)\n",
    "\n",
    "    # Преобразование результатов в формат torch.Tensor для сравнения с PyTorch\n",
    "    input_tensor_torch = torch.tensor(input_tensor)\n",
    "    stride_h, stride_w = conv_transpose_layer.stride if isinstance(conv_transpose_layer.stride, tuple) else (conv_transpose_layer.stride, conv_transpose_layer.stride)\n",
    "\n",
    "    output_tensor_torch = torch.nn.functional.conv_transpose2d(\n",
    "        input_tensor_torch,\n",
    "        torch.tensor(conv_transpose_layer.weights),\n",
    "        bias=torch.tensor(conv_transpose_layer.bias),\n",
    "        stride=(stride_h, stride_w),\n",
    "        padding=padding,\n",
    "        output_padding=stride_h - 1,\n",
    "        dilation=dilation,\n",
    "        groups=groups\n",
    "    ).numpy()\n",
    "\n",
    "    # Обрезание результатов из Conv2DTranspose, чтобы сделать размеры одинаковыми\n",
    "    min_height = min(result_conv2d_transpose.shape[2], output_tensor_torch.shape[2])\n",
    "    min_width = min(result_conv2d_transpose.shape[3], output_tensor_torch.shape[3])\n",
    "    result_conv2d_transpose = result_conv2d_transpose[:, :, :min_height, :min_width]\n",
    "    output_tensor_torch = output_tensor_torch[:, :, :min_height, :min_width]\n",
    "\n",
    "    # Проверка совпадения результатов\n",
    "    are_results_equal = np.allclose(result_conv2d_transpose, output_tensor_torch)\n",
    "\n",
    "    # Вывод результатов теста\n",
    "    print(f\"Тест с параметрами:\")\n",
    "    print(f\"  - in_channels: {in_channels}\")\n",
    "    print(f\"  - out_channels: {out_channels}\")\n",
    "    print(f\"  - kernel_size: {kernel_size}\")\n",
    "    print(f\"  - stride: {stride}\")\n",
    "    print(f\"  - padding: {padding}\")\n",
    "    print(f\"  - dilation: {dilation}\")\n",
    "    print(f\"  - groups: {groups}\")\n",
    "    print(f\"  - bias: {bias}\")\n",
    "    print(f\"  - padding_mode: {padding_mode}\")\n",
    "    print(f\"\\nРезультат транспонированной свертки совпадает: {are_results_equal}\")\n",
    "    print(f\"\\n{'-' * 75}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ab8da5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_transpose_params():\n",
    "    # параметры тестирования для первой группы\n",
    "    run_transpose_test(in_channels=3, out_channels=2, kernel_size=3, stride=(2, 2), padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "\n",
    "    # параметры тестирования для второй группы\n",
    "    run_transpose_test(in_channels=4, out_channels=2, kernel_size=(2, 3), stride=(2, 3), padding=(1, 1), dilation=1, groups=1, bias=True, padding_mode='replicate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "36d32d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тест с параметрами:\n",
      "  - in_channels: 3\n",
      "  - out_channels: 2\n",
      "  - kernel_size: 3\n",
      "  - stride: (2, 2)\n",
      "  - padding: 0\n",
      "  - dilation: 1\n",
      "  - groups: 1\n",
      "  - bias: True\n",
      "  - padding_mode: zeros\n",
      "\n",
      "Результат транспонированной свертки совпадает: True\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Тест с параметрами:\n",
      "  - in_channels: 4\n",
      "  - out_channels: 2\n",
      "  - kernel_size: (2, 3)\n",
      "  - stride: (2, 3)\n",
      "  - padding: (1, 1)\n",
      "  - dilation: 1\n",
      "  - groups: 1\n",
      "  - bias: True\n",
      "  - padding_mode: replicate\n",
      "\n",
      "Результат транспонированной свертки совпадает: False\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_transpose_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933a6da8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
